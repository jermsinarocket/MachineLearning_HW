{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33333333]\n",
      " [-0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "#PROBLEM 6(B)\n",
    "\n",
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "\n",
    "A = np.array([[2, 0], [-1, 1], [0, 2]])\n",
    "b = np.array([[1], [0], [-1]])\n",
    "\n",
    "x = cvx.Variable([2,1])\n",
    "\n",
    "\n",
    "obj = cvx.Minimize(cvx.norm(A*x-b, 2))\n",
    "prob = cvx.Problem(obj)\n",
    "result = prob.solve()\n",
    "\n",
    "print(x.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PROBLEM 7\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "#We are loading image from url, ensure urllib3 is installed (pip install urllib3)\n",
    "def url_to_image(url):\n",
    "    # download the image, convert it to a NumPy array, and then read\n",
    "    # it into OpenCV format\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    " \n",
    "    # return the image\n",
    "    return image\n",
    "\n",
    "\n",
    "list_of_img_paths = [\"https://www.dropbox.com/s/2btds50ozow42sq/panorama_postech_left.jpg?dl=1\",\"https://www.dropbox.com/s/o3z0vbpo0ab4g9l/panorama_postech_front.jpg?dl=1\",\"https://www.dropbox.com/s/2bttukco3v701yt/panorama_postech_right.jpg?dl=1\"]\n",
    "\n",
    "all_images = []\n",
    "\n",
    "#Load Images\n",
    "\n",
    "#Read all the images and store it into an array\n",
    "for i in range(len(list_of_img_paths)):\n",
    "    all_images.append(cv2.imdecode(url_to_image(list_of_img_paths[i]),cv2.IMREAD_COLOR))\n",
    "\n",
    "pos1 = np.array([[2121, 2117, 2749, 3095, 3032, 3375, 3677, 3876], \n",
    "                 [1431, 2034, 2033, 1885, 2017, 2037, 1885, 2279]], dtype=np.int64)\n",
    "pos2 = np.array([[188, 58, 828, 1203, 1121, 1437, 1717, 1817], \n",
    "                 [1217, 1909, 1952, 1827, 1952, 1991, 1870, 2226]], dtype=np.int64)\n",
    "pos3 = np.array([[2338, 2379, 2658, 2899, 2977, 3272, 2716, 2786], \n",
    "                 [1948, 1874, 2000, 1837, 1964, 1966, 2143, 2317]], dtype=np.int64)\n",
    "pos4 = np.array([[109, 178, 497, 795, 851, 1144, 534, 580], \n",
    "                 [1907, 1828, 1988, 1834, 1971, 1993, 2145, 2333]], dtype=np.int64)\n",
    "\n",
    "\n",
    "#Code to Display and Mark matching points on image\n",
    "fig = plt.figure(figsize=(50,50))\n",
    "\n",
    "\n",
    "#Visualization of Key Points\n",
    "for i in range(3):\n",
    "    sub = fig.add_subplot(1, 3, i + 1)\n",
    "    \n",
    "    # We need to do this as cv2 reads image in BGR format while matplotlib reads images in RGB format\n",
    "    \n",
    "    all_images[i] = cv2.cvtColor(all_images[i], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    sub.imshow(all_images[i], interpolation='nearest')\n",
    "    \n",
    "    scatterSize = 300\n",
    "    markerColour = 'red'\n",
    "\n",
    "    if(i == 0):\n",
    "        \n",
    "        x = pos1[0,:]\n",
    "        y = pos1[1,:]\n",
    "        sub.scatter(x,y,scatterSize,markerColour)\n",
    "\n",
    "        \n",
    "    elif(i == 1):\n",
    "        x = pos2[0,:]\n",
    "        y = pos2[1,:]\n",
    "        z = pos3[0,:] \n",
    "        u  = pos3[1,:]\n",
    "        sub.scatter(x,y,scatterSize, markerColour)\n",
    "        sub.scatter(z,u,scatterSize, markerColour)\n",
    "        \n",
    "    elif(i == 2):\n",
    "        z = pos4[0,:] \n",
    "        u  = pos4[1,:]\n",
    "        sub.scatter(z,u,scatterSize, markerColour)\n",
    "        \n",
    "    #Change whitespaces between images\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0) \n",
    "    #Remove axis from subplots\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "\n",
    "\n",
    "    \n",
    "# Perspective homography for image 1 and image 2\n",
    "pers_h1 = np.zeros((16, 8))\n",
    "column_1 = np.zeros((16, 1))\n",
    "\n",
    "#Construct Feature Matrix for Image 1 and 2\n",
    "for i in range(0,8):\n",
    "    #Feature Matrix\n",
    "    pers_h1[2*i,:] = np.array([[pos1[0, i], pos1[1, i], 1, 0, 0, 0, -pos2[0, i]*pos1[0, i], -pos2[0, i]*pos1[1,i]]])\n",
    "    pers_h1[2*i+1,:] = np.array([[0, 0, 0, pos1[0, i], pos1[1, i], 1, -pos2[1, i]*pos1[0, i], -pos2[1, i]*pos1[1, i]]])\n",
    "    \n",
    "    #Column vector for corresponding positions in the base image\n",
    "    column_1[2*i, :] = np.array([[pos2[0, i]]])\n",
    "    column_1[2*i+1, :] = np.array([[pos2[1, i]]])\n",
    "    \n",
    "# Define perspective_theta using linear regression    \n",
    "perspective_theta = np.linalg.inv(pers_h1.transpose().dot(pers_h1)).dot(pers_h1.transpose()).dot(column_1)\n",
    "perspective_theta = np.concatenate((perspective_theta, np.ones((1,1))), 0)\n",
    "#Reshape for multiplication later on\n",
    "perspective_theta = np.reshape(perspective_theta, (3,3))\n",
    "\n",
    "\n",
    "#Perspective homography for image 2 and 3\n",
    "pers_h2 = np.zeros((16, 8))\n",
    "newpos02 = np.zeros((16, 1))\n",
    "\n",
    "#Construct feature matrix for Image 1 and 2\n",
    "for i in range(0, 8):\n",
    "    #Feature Matrix\n",
    "    pers_h2[2*i,:] = np.array([[pos3[0, i], pos3[1, i], 1, 0, 0, 0, -pos4[0, i]*pos3[0, i], -pos4[0, i]*pos3[1,i]]])\n",
    "    pers_h2[2*i+1,:] = np.array([[0, 0, 0, pos3[0, i], pos3[1, i], 1, -pos4[1, i]*pos3[0, i], -pos4[1, i]*pos3[1, i]]])\n",
    "    #Column vector for corresponding positions in the base image\n",
    "    newpos02[2*i, :] = np.array([[pos4[0, i]]])\n",
    "    newpos02[2*i+1, :] = np.array([[pos4[1, i]]])\n",
    "    \n",
    "    \n",
    "perspective_theta3 = np.linalg.inv(pers_h2.transpose().dot(pers_h2)).dot(pers_h2.transpose()).dot(column_2)\n",
    "perspective_theta3 = np.concatenate((perspective_theta3, np.ones((1,1))), 0)\n",
    "#Reshape for multiplication later on\n",
    "perspective_theta3 = np.reshape(perspective_theta2, (3,3))\n",
    "\n",
    "\n",
    "#Image Wrapping\n",
    "translation = np.matrix([[1, 0, 6000],\n",
    "                         [0, 1, 2500],\n",
    "                         [0, 0, 1]])\n",
    "\n",
    "warpedImage = cv2.warpPerspective(all_images[0], translation*perspective_theta, (18000, 6500))\n",
    "warpedImage3 = cv2.warpPerspective(all_images[2], translation*perspective_theta3, (18000, 6500))\n",
    "screen = warpedImage.copy()\n",
    "screen[screen==0] = warpedImage3[screen==0]\n",
    "screen[2500:3024+2500,6000:4032+6000] = all_images[1]\n",
    "\n",
    "\n",
    "## Visualize panorama image\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.imshow(screen)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
